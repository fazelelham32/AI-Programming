The Pac-Man Projects
Logical agent design:
What does this Pacman understand about the environment?
- He sees the place of souls. - He sees the location of the food. - Where is he?
- Where is the obstacle, energy capsules
The operation it performs moves in 4 directions.
He should be able to eat all the food with minimal movements
One point is deducted for each move he makes.

Overview
The Pac-Man projects were developed for CS 188. They apply an array of AI techniques to playing Pac-Man. However, these projects don't focus on building AI for video games. Instead, they teach foundational AI concepts, such as informed state-space search, probabilistic inference, and reinforcement learning. These concepts underly real-world application areas such as natural language processing, computer vision, and robotics.
We designed these projects with three goals in mind. The projects allow you to visualize the results of the techniques you implement. They also contain code examples and clear directions but do not force you to wade through undue amounts of scaffolding. Finally, Pac-Man provides a challenging problem environment that demands creative solutions; real-world AI problems are challenging, and Pac-Man is too. 

Projects Overview 
P0: UNIX/Python Tutorial 
This short UNIX/Python tutorial introduces students to the Python programming language and the UNIX environment.

P1: Search 
Students implement depth-first, breadth-first, uniform cost, and A* search algorithms. These algorithms are used to solve navigation and traveling salesman problems in the Pacman world. 

Mini-Contest 1: Multi-Agent Pacman 
Students will apply the search algorithms and problems implemented in Project 1 to handle more difficult scenarios that include controlling multiple pacman agents and planning under time constraints 

P2: Multi-Agent Search 
Classic Pacman is modeled as both an adversarial and a stochastic search problem. Students implement multiagent minimax and expectimax algorithms, as well as design evaluation functions.

Mini-Contest 2: Multi-Agent Adversarial Pacman 
This mini-contest involves a multiplayer capture-the-flag variant of Pacman, where agents control both Pacman and ghosts in coordinated team-based strategies. Each team will try to eat the food on the far side of the map while defending the food on their home side.

P3: Reinforcement Learning 
Students implement model-based and model-free reinforcement learning algorithms, applied to the AIMA textbook's Gridworld, Pacman, and a simulated crawling robot. 

P4: Ghostbusters 
Probabilistic inference in a hidden Markov model tracks the movement of hidden ghosts in the Pacman world. Students implement exact inference using the forward algorithm and approximate inference via particle filters. 

P5: Machine Learning 
Students implement the perceptron algorithm and neural network models and apply the models to several tasks including digit classification. 

Contest: Pacman Capture the Flag 
Students create strategies for a team of two agents to play a multi-player capture-the-flag variant of Pacman. 

Technical Notes
The Pac-Man projects are written in pure Python 3.6 and do not depend on any packages external to a standard Python distribution. 

Support
This project was supported by the National Science Foundation under CAREER grant 0643742. Any opinions, findings conclusions, or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation (NSF). 

Credits
The projects were developed by John DeNero, Dan Klein, Pieter Abbeel, and many others. 


Why Python for AI?
Because it has support for pre-built libraries python is very convenient for AI developers because all of the algorithms machine learning algorithms and deep learning algorithms are already predefined in libraries right so you don’t have to actually sit down and code each and every algorithm that will take a lot of time and that’s a very time-consuming task 

Introduction to AI for video games:
Data scientists will hire humans to hand label their data sets using services like Amazon’s Mechanical Turk, but ideally, we don’t need labels we can just train our algorithms on unlabelled data since the vast majority of the world’s data does not in fact have labels so if we want to train unsupervised meaning to labels, then we can use techniques like clustering and anomaly detection these are fast improving but there’s also room for another class of learning techniques that are based on trial and error in an environment setting this is called reinforcement learning the basic idea is that in RL the labels are time delayed and instead of calling them labels we call them rewards while supervised learning tells you to have to achieve your goal RL tells you how well you achieved the goal there are lots of problem settings where the idea of?
Time-delayed labels make more sense think about if you were tasked with creating an AI that learns how best to control the temperature in a data center. How are you going to tell your algorithm?
Robotics has been a testbed for RL research for decades there have been several successes in getting RL agents to learn to play sports navigate a helicopter autonomously gain robots to walk and get them to full of laundry
We’ve created some seriously capable robots that are theoretically able to do any task a healthy human could do but the reason they’re still so limited is because software robotics is a software problem not a hardware problem in parallel to the robotics world game environments have also been a testbed for RL since they are safer than the real world and the barrier to entry is just having a laptop so anyone can test our their algorithms two of the most popular AL research institutions in the world open AI and deep mind extensively use game environments to train and test their algorithms and their world-class. 
The simple game of tic-tac-toe 
Where the goal is to be the first to successfully create three in a row and we have our AI which we’ll call an agent our goal is to have this AI learn how to become really good at playing tic-tac-toe against humans rather than just hard coding in a bunch of if-then statements how can we formalize this problem?


